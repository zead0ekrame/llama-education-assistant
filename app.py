#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ - Hugging Face Space
"""

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import whisper
from gtts import gTTS
import tempfile
import os
from datetime import datetime

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
MODEL_NAME = "microsoft/DialoGPT-medium"
# HF_TOKEN = "YOUR_HUGGING_FACE_TOKEN_HERE"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

# ØªØ­Ù…ÙŠÙ„ Whisper
print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Whisper...")
whisper_model = whisper.load_model("base")

print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬!")

# Ø¯ÙˆØ§Ù„ TTS Ùˆ STT
def text_to_speech(text, language='ar'):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…"""
    try:
        tts = gTTS(text=text, lang=language, slow=False)
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
            tts.save(tmp_file.name)
            return tmp_file.name
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ TTS: {e}")
        return None

def speech_to_text(audio_file):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ"""
    try:
        result = whisper_model.transcribe(audio_file, language="ar")
        return result["text"].strip()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ STT: {e}")
        return "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø§Ù„ÙƒÙ„Ø§Ù…"

def chat_with_model(user_input):
    """Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    try:
        # Ø¥Ø¹Ø¯Ø§Ø¯ prompt Ù„Ù„ØªØ¹Ù„ÙŠÙ…
        prompt = f"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø°ÙƒÙŠ. Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨: {user_input}"
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        response = pipe(
            prompt,
            max_length=200,
            num_return_sequences=1,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        generated_text = response[0]['generated_text']
        answer = generated_text.replace(prompt, "").strip()
        
        return answer
    except Exception as e:
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"

def voice_chat(audio_file):
    """Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„ØµÙˆØªÙŠ"""
    if audio_file is None:
        return "Ù…Ù† ÙØ¶Ù„Ùƒ Ø³Ø¬Ù„ ØµÙˆØªÙƒ", None
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ
    user_text = speech_to_text(audio_file)
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©
    response = chat_with_model(user_text)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…
    audio_response = text_to_speech(response)
    
    return f"ğŸ¤ Ø³Ø¤Ø§Ù„Ùƒ: {user_text}\n\nğŸ¤– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {response}", audio_response

# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Gradio
def create_interface():
    with gr.Blocks(
        title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1200px !important;
            margin: auto !important;
        }
        """
    ) as interface:
        
        gr.Markdown("""
        # ğŸ“ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ
        
        Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø°ÙƒÙŠ ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ§Ù„ØªÙØ§Ø¹Ù„ Ø¹Ø¨Ø± Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØª.
        
        **Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:**
        - ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ© Ø°ÙƒÙŠØ©
        - ğŸ¤ Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ©
        - ğŸ“š Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©
        - ğŸ¤– Ø¥Ø¬Ø§Ø¨Ø§Øª ÙÙˆØ±ÙŠØ©
        """)
        
        with gr.Tabs():
            with gr.Tab("ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ©"):
                with gr.Row():
                    with gr.Column(scale=3):
                        text_input = gr.Textbox(
                            label="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§",
                            placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ",
                            lines=3
                        )
                        text_btn = gr.Button("Ø¥Ø±Ø³Ø§Ù„", variant="primary", size="lg")
                    
                    with gr.Column(scale=2):
                        text_output = gr.Textbox(
                            label="Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©",
                            lines=10,
                            interactive=False
                        )
                
                text_btn.click(
                    chat_with_model,
                    inputs=text_input,
                    outputs=text_output
                )
            
            with gr.Tab("ğŸ¤ Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ©"):
                with gr.Row():
                    with gr.Column(scale=2):
                        audio_input = gr.Audio(
                            label="Ø³Ø¬Ù„ ØµÙˆØªÙƒ",
                            type="filepath",
                            format="mp3"
                        )
                        voice_btn = gr.Button("Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª", variant="primary", size="lg")
                    
                    with gr.Column(scale=3):
                        voice_output = gr.Textbox(
                            label="Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
                            lines=8,
                            interactive=False
                        )
                        audio_output = gr.Audio(
                            label="Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµÙˆØªÙŠØ©",
                            type="filepath"
                        )
                
                voice_btn.click(
                    voice_chat,
                    inputs=audio_input,
                    outputs=[voice_output, audio_output]
                )
        
        gr.Markdown("""
        ---
        **ğŸ’¡ Ù†ØµØ§Ø¦Ø­:**
        - Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø©
        - ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£ÙŠ Ù…ÙˆØ¶ÙˆØ¹ ØªØ¹Ù„ÙŠÙ…ÙŠ
        - Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ØªØ¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        """)
    
    return interface

# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
if __name__ == "__main__":
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False  # ÙÙŠ Hugging Face Spaces
    )
