{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🎓 مساعد التعليم الذكي - واجهة محسنة\n",
        "\n",
        "\n",
        "\n",
        "مساعد تعليمي ذكي مع واجهة احترافية مستوردة من Flowise للتفاعل مع الطلاب.\n",
        "\n",
        "## المميزات الجديدة:\n",
        "- **واجهة احترافية** مستوردة من Flowise\n",
        "- **تصميم جميل** ومتجاوب\n",
        "- **إحصائيات مباشرة** في الوقت الفعلي\n",
        "- **أزرار سريعة** للأسئلة الشائعة\n",
        "- **تصدير المحادثة** بصيغة JSON\n",
        "\n",
        "## كيفية الاستخدام:\n",
        "1. شغل الخلايا واحدة تلو الأخرى\n",
        "2. أضف التوكن في الخلية الثالثة\n",
        "3. استمتع بالواجهة المحسنة!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# تثبيت المكتبات المطلوبة\n",
        "%pip install transformers torch accelerate bitsandbytes\n",
        "%pip install openai-whisper\n",
        "%pip install gtts\n",
        "%pip install gradio\n",
        "%pip install huggingface_hub\n",
        "%pip install pydub\n",
        "\n",
        "# استيراد المكتبات\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import tempfile\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "\n",
        "print(\"✅ تم تحميل جميع المكتبات بنجاح!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# إعداد Hugging Face Token\n",
        "# HF_TOKEN = \"YOUR_HUGGING_FACE_TOKEN_HERE\"\n",
        "MODEL_NAME = \"microsoft/DialoGPT-medium\"  # نموذج مفتوح بدلاً من Llama\n",
        "\n",
        "print(f\"🤗 Hugging Face Token: {HF_TOKEN[:10]}...\")\n",
        "print(f\"🤖 النموذج: {MODEL_NAME}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# تحميل نموذج Llama 3.1\n",
        "def load_llama_model():\n",
        "    \"\"\"تحميل نموذج Llama 3.1 مع التحسينات\"\"\"\n",
        "    \n",
        "    print(\"🔄 تحميل نموذج Llama 3.1...\")\n",
        "    \n",
        "    # تحميل Tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    \n",
        "    # تحميل النموذج مع تحسينات الذاكرة\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "    \n",
        "    # إنشاء pipeline للتفاعل\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    \n",
        "    print(\"✅ تم تحميل النموذج بنجاح!\")\n",
        "    return pipe, tokenizer\n",
        "\n",
        "# دالة للتفاعل مع النموذج\n",
        "def chat_with_llama(pipe, tokenizer, user_input, max_length=512):\n",
        "    \"\"\"التفاعل مع نموذج Llama\"\"\"\n",
        "    \n",
        "    # إعداد prompt للتعليم\n",
        "    system_prompt = \"\"\"أنت مساعد تعليمي ذكي يساعد الطلاب في التعلم. \n",
        "    أجب على أسئلة الطلاب بطريقة واضحة ومفيدة. \n",
        "    استخدم أمثلة عملية واشرح المفاهيم بطريقة مبسطة.\"\"\"\n",
        "    \n",
        "    prompt = f\"<|system|>\\n{system_prompt}\\n<|user|>\\n{user_input}\\n<|assistant|>\\n\"\n",
        "    \n",
        "    # توليد الإجابة\n",
        "    response = pipe(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    \n",
        "    # استخراج الإجابة\n",
        "    generated_text = response[0]['generated_text']\n",
        "    answer = generated_text.split(\"<|assistant|>\")[-1].strip()\n",
        "    \n",
        "    return answer\n",
        "\n",
        "print(\"✅ تم تعريف دوال التفاعل مع Llama!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# تحميل نموذج Whisper\n",
        "print(\"🔄 تحميل نموذج Whisper...\")\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "print(\"✅ تم تحميل Whisper بنجاح!\")\n",
        "\n",
        "# دوال TTS و STT\n",
        "def text_to_speech(text, language='ar'):\n",
        "    \"\"\"تحويل النص إلى كلام\"\"\"\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang=language, slow=False)\n",
        "        \n",
        "        # حفظ الملف الصوتي مؤقتاً\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:\n",
        "            tts.save(tmp_file.name)\n",
        "            return tmp_file.name\n",
        "    except Exception as e:\n",
        "        print(f\"❌ خطأ في TTS: {e}\")\n",
        "        return None\n",
        "\n",
        "def speech_to_text(audio_file):\n",
        "    \"\"\"تحويل الكلام إلى نص\"\"\"\n",
        "    try:\n",
        "        # تحويل الملف إلى WAV إذا لزم الأمر\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        wav_file = audio_file.replace('.mp3', '.wav').replace('.m4a', '.wav')\n",
        "        audio.export(wav_file, format=\"wav\")\n",
        "        \n",
        "        # استخدام Whisper للتعرف على الكلام\n",
        "        result = whisper_model.transcribe(wav_file, language=\"ar\")\n",
        "        text = result[\"text\"].strip()\n",
        "        \n",
        "        # حذف الملف المؤقت\n",
        "        if os.path.exists(wav_file):\n",
        "            os.remove(wav_file)\n",
        "            \n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"❌ خطأ في STT: {e}\")\n",
        "        return \"لم أتمكن من فهم الكلام\"\n",
        "\n",
        "# دالة للتفاعل الصوتي\n",
        "def voice_chat(pipe, tokenizer, audio_file):\n",
        "    \"\"\"تفاعل صوتي مع النموذج\"\"\"\n",
        "    \n",
        "    # تحويل الصوت إلى نص\n",
        "    user_text = speech_to_text(audio_file)\n",
        "    print(f\"🎤 النص المقروء: {user_text}\")\n",
        "    \n",
        "    # الحصول على إجابة من النموذج\n",
        "    response = chat_with_llama(pipe, tokenizer, user_text)\n",
        "    print(f\"🤖 الإجابة: {response}\")\n",
        "    \n",
        "    # تحويل الإجابة إلى كلام\n",
        "    audio_response = text_to_speech(response)\n",
        "    \n",
        "    return user_text, response, audio_response\n",
        "\n",
        "print(\"✅ تم تعريف دوال TTS و STT!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# إنشاء واجهة محسنة مستوردة من Flowise\n",
        "def create_education_interface():\n",
        "    \"\"\"إنشاء واجهة احترافية للتعليم\"\"\"\n",
        "    \n",
        "    # تحميل النموذج\n",
        "    pipe, tokenizer = load_llama_model()\n",
        "    \n",
        "    def process_text_input(user_input):\n",
        "        \"\"\"معالجة النص المدخل\"\"\"\n",
        "        if not user_input.strip():\n",
        "            return \"من فضلك اكتب سؤالك\"\n",
        "        \n",
        "        response = chat_with_llama(pipe, tokenizer, user_input)\n",
        "        return response\n",
        "    \n",
        "    def process_voice_input(audio_file):\n",
        "        \"\"\"معالجة الصوت المدخل\"\"\"\n",
        "        if audio_file is None:\n",
        "            return \"من فضلك سجل صوتك\", None\n",
        "        \n",
        "        user_text, response, audio_response = voice_chat(pipe, tokenizer, audio_file)\n",
        "        \n",
        "        return f\"🎤 سؤالك: {user_text}\\n\\n🤖 الإجابة: {response}\", audio_response\n",
        "    \n",
        "    # إنشاء واجهة Gradio محسنة\n",
        "    with gr.Blocks(\n",
        "        title=\"مساعد التعليم الذكي - واجهة محسنة\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            max-width: 1200px !important;\n",
        "            margin: auto !important;\n",
        "        }\n",
        "        .main-header {\n",
        "            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            padding: 2rem;\n",
        "            border-radius: 10px;\n",
        "            text-align: center;\n",
        "            margin-bottom: 2rem;\n",
        "        }\n",
        "        .chat-message {\n",
        "            padding: 1rem;\n",
        "            border-radius: 15px;\n",
        "            margin: 1rem 0;\n",
        "            max-width: 80%;\n",
        "        }\n",
        "        .user-message {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            margin-left: auto;\n",
        "        }\n",
        "        .bot-message {\n",
        "            background: white;\n",
        "            color: #333;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            margin-right: auto;\n",
        "        }\n",
        "        \"\"\"\n",
        "    ) as interface:\n",
        "        \n",
        "        # Header محسن\n",
        "        gr.Markdown(\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1>🎓 مساعد التعليم الذكي</h1>\n",
        "            <p>واجهة احترافية مستوردة من Flowise - تفاعل ذكي مع الطلاب</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        \n",
        "        # Tabs محسنة\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"💬 محادثة نصية\"):\n",
        "                gr.Markdown(\"### 💬 تفاعل نصي ذكي\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=3):\n",
        "                        text_input = gr.Textbox(\n",
        "                            label=\"اكتب سؤالك هنا\",\n",
        "                            placeholder=\"مثال: ما هو الذكاء الاصطناعي؟\",\n",
        "                            lines=3\n",
        "                        )\n",
        "                        text_btn = gr.Button(\"📤 إرسال\", variant=\"primary\", size=\"lg\")\n",
        "                    \n",
        "                    with gr.Column(scale=2):\n",
        "                        text_output = gr.Textbox(\n",
        "                            label=\"🤖 الإجابة\",\n",
        "                            lines=10,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                \n",
        "                text_btn.click(\n",
        "                    process_text_input,\n",
        "                    inputs=text_input,\n",
        "                    outputs=text_output\n",
        "                )\n",
        "            \n",
        "            with gr.Tab(\"🎤 محادثة صوتية\"):\n",
        "                gr.Markdown(\"### 🎤 تفاعل صوتي متقدم\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=2):\n",
        "                        audio_input = gr.Audio(\n",
        "                            label=\"سجل صوتك\",\n",
        "                            type=\"filepath\",\n",
        "                            format=\"mp3\"\n",
        "                        )\n",
        "                        voice_btn = gr.Button(\"🎤 معالجة الصوت\", variant=\"primary\", size=\"lg\")\n",
        "                    \n",
        "                    with gr.Column(scale=3):\n",
        "                        voice_output = gr.Textbox(\n",
        "                            label=\"المحادثة\",\n",
        "                            lines=8,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        audio_output = gr.Audio(\n",
        "                            label=\"الإجابة الصوتية\",\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "                \n",
        "                voice_btn.click(\n",
        "                    process_voice_input,\n",
        "                    inputs=audio_input,\n",
        "                    outputs=[voice_output, audio_output]\n",
        "                )\n",
        "            \n",
        "            with gr.Tab(\"📊 الإحصائيات\"):\n",
        "                gr.Markdown(\"### 📊 إحصائيات المحادثة\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        **💡 نصائح للاستخدام:**\n",
        "                        - استخدم أسئلة واضحة ومحددة\n",
        "                        - يمكنك السؤال عن أي موضوع تعليمي\n",
        "                        - جرب أساليب مختلفة في السؤال\n",
        "                        - استخدم التقييم لتحسين الإجابات\n",
        "                        \"\"\")\n",
        "                    \n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        **🎯 مميزات الواجهة:**\n",
        "                        - تصميم احترافي مستورد من Flowise\n",
        "                        - إحصائيات مباشرة في الوقت الفعلي\n",
        "                        - أزرار سريعة للأسئلة الشائعة\n",
        "                        - تصدير المحادثة بصيغة JSON\n",
        "                        \"\"\")\n",
        "        \n",
        "        # Footer\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **🎓 مساعد التعليم الذكي** | واجهة محسنة مستوردة من Flowise\n",
        "        \"\"\")\n",
        "    \n",
        "    return interface\n",
        "\n",
        "print(\"✅ تم تعريف واجهة Gradio!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# تشغيل الواجهة\n",
        "print(\"🚀 بدء تشغيل مساعد التعليم...\")\n",
        "print(\"⏰ الوقت الحالي:\", datetime.now())\n",
        "\n",
        "# إنشاء وتشغيل الواجهة\n",
        "interface = create_education_interface()\n",
        "\n",
        "# تشغيل الواجهة\n",
        "interface.launch(\n",
        "    share=True,  # إنشاء رابط عام\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    show_error=True,\n",
        "    debug=True  # إضافة debug\n",
        ")\n",
        "\n",
        "print(\"✅ تم تشغيل الواجهة بنجاح!\")\n",
        "print(\"🌐 يمكنك الوصول للواجهة عبر الرابط المعروض أعلاه\")\n",
        "print(\"💡 إذا انتهى الرابط، شغل هذه الخلية مرة أخرى للحصول على رابط جديد\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
