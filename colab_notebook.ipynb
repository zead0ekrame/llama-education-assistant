{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ - ÙˆØ§Ø¬Ù‡Ø© Ù…Ø­Ø³Ù†Ø©\n",
        "\n",
        "\n",
        "\n",
        "Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø°ÙƒÙŠ Ù…Ø¹ ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ø³ØªÙˆØ±Ø¯Ø© Ù…Ù† Flowise Ù„Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ø·Ù„Ø§Ø¨.\n",
        "\n",
        "## Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:\n",
        "- **ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©** Ù…Ø³ØªÙˆØ±Ø¯Ø© Ù…Ù† Flowise\n",
        "- **ØªØµÙ…ÙŠÙ… Ø¬Ù…ÙŠÙ„** ÙˆÙ…ØªØ¬Ø§ÙˆØ¨\n",
        "- **Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ø¨Ø§Ø´Ø±Ø©** ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ\n",
        "- **Ø£Ø²Ø±Ø§Ø± Ø³Ø±ÙŠØ¹Ø©** Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©\n",
        "- **ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©** Ø¨ØµÙŠØºØ© JSON\n",
        "\n",
        "## ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:\n",
        "1. Ø´ØºÙ„ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ ÙˆØ§Ø­Ø¯Ø© ØªÙ„Ùˆ Ø§Ù„Ø£Ø®Ø±Ù‰\n",
        "2. Ø£Ø¶Ù Ø§Ù„ØªÙˆÙƒÙ† ÙÙŠ Ø§Ù„Ø®Ù„ÙŠØ© Ø§Ù„Ø«Ø§Ù„Ø«Ø©\n",
        "3. Ø§Ø³ØªÙ…ØªØ¹ Ø¨Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
        "%pip install transformers torch accelerate bitsandbytes\n",
        "%pip install openai-whisper\n",
        "%pip install gtts\n",
        "%pip install gradio\n",
        "%pip install huggingface_hub\n",
        "%pip install pydub\n",
        "\n",
        "# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import tempfile\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ø¥Ø¹Ø¯Ø§Ø¯ Hugging Face Token\n",
        "# HF_TOKEN = \"YOUR_HUGGING_FACE_TOKEN_HERE\"\n",
        "MODEL_NAME = \"microsoft/DialoGPT-medium\"  # Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØªÙˆØ­ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Llama\n",
        "\n",
        "print(f\"ğŸ¤— Hugging Face Token: {HF_TOKEN[:10]}...\")\n",
        "print(f\"ğŸ¤– Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_NAME}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Llama 3.1\n",
        "def load_llama_model():\n",
        "    \"\"\"ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Llama 3.1 Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª\"\"\"\n",
        "    \n",
        "    print(\"ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Llama 3.1...\")\n",
        "    \n",
        "    # ØªØ­Ù…ÙŠÙ„ Tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    \n",
        "    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "    \n",
        "    # Ø¥Ù†Ø´Ø§Ø¡ pipeline Ù„Ù„ØªÙØ§Ø¹Ù„\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "    return pipe, tokenizer\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ù„Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "def chat_with_llama(pipe, tokenizer, user_input, max_length=512):\n",
        "    \"\"\"Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ Llama\"\"\"\n",
        "    \n",
        "    # Ø¥Ø¹Ø¯Ø§Ø¯ prompt Ù„Ù„ØªØ¹Ù„ÙŠÙ…\n",
        "    system_prompt = \"\"\"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø°ÙƒÙŠ ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù…. \n",
        "    Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙŠØ¯Ø©. \n",
        "    Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© ÙˆØ§Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø³Ø·Ø©.\"\"\"\n",
        "    \n",
        "    prompt = f\"<|system|>\\n{system_prompt}\\n<|user|>\\n{user_input}\\n<|assistant|>\\n\"\n",
        "    \n",
        "    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\n",
        "    response = pipe(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    \n",
        "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\n",
        "    generated_text = response[0]['generated_text']\n",
        "    answer = generated_text.split(\"<|assistant|>\")[-1].strip()\n",
        "    \n",
        "    return answer\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ¹Ø±ÙŠÙ Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Llama!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper\n",
        "print(\"ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper...\")\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Whisper Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "\n",
        "# Ø¯ÙˆØ§Ù„ TTS Ùˆ STT\n",
        "def text_to_speech(text, language='ar'):\n",
        "    \"\"\"ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…\"\"\"\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang=language, slow=False)\n",
        "        \n",
        "        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ù…Ø¤Ù‚ØªØ§Ù‹\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:\n",
        "            tts.save(tmp_file.name)\n",
        "            return tmp_file.name\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ TTS: {e}\")\n",
        "        return None\n",
        "\n",
        "def speech_to_text(audio_file):\n",
        "    \"\"\"ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ\"\"\"\n",
        "    try:\n",
        "        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ WAV Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        wav_file = audio_file.replace('.mp3', '.wav').replace('.m4a', '.wav')\n",
        "        audio.export(wav_file, format=\"wav\")\n",
        "        \n",
        "        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…\n",
        "        result = whisper_model.transcribe(wav_file, language=\"ar\")\n",
        "        text = result[\"text\"].strip()\n",
        "        \n",
        "        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª\n",
        "        if os.path.exists(wav_file):\n",
        "            os.remove(wav_file)\n",
        "            \n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ STT: {e}\")\n",
        "        return \"Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø§Ù„ÙƒÙ„Ø§Ù…\"\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ù„Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„ØµÙˆØªÙŠ\n",
        "def voice_chat(pipe, tokenizer, audio_file):\n",
        "    \"\"\"ØªÙØ§Ø¹Ù„ ØµÙˆØªÙŠ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\"\"\"\n",
        "    \n",
        "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ\n",
        "    user_text = speech_to_text(audio_file)\n",
        "    print(f\"ğŸ¤ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø±ÙˆØ¡: {user_text}\")\n",
        "    \n",
        "    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "    response = chat_with_llama(pipe, tokenizer, user_text)\n",
        "    print(f\"ğŸ¤– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {response}\")\n",
        "    \n",
        "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…\n",
        "    audio_response = text_to_speech(response)\n",
        "    \n",
        "    return user_text, response, audio_response\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ¹Ø±ÙŠÙ Ø¯ÙˆØ§Ù„ TTS Ùˆ STT!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø³ØªÙˆØ±Ø¯Ø© Ù…Ù† Flowise\n",
        "def create_education_interface():\n",
        "    \"\"\"Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù„Ù„ØªØ¹Ù„ÙŠÙ…\"\"\"\n",
        "    \n",
        "    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "    pipe, tokenizer = load_llama_model()\n",
        "    \n",
        "    def process_text_input(user_input):\n",
        "        \"\"\"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„\"\"\"\n",
        "        if not user_input.strip():\n",
        "            return \"Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ\"\n",
        "        \n",
        "        response = chat_with_llama(pipe, tokenizer, user_input)\n",
        "        return response\n",
        "    \n",
        "    def process_voice_input(audio_file):\n",
        "        \"\"\"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¯Ø®Ù„\"\"\"\n",
        "        if audio_file is None:\n",
        "            return \"Ù…Ù† ÙØ¶Ù„Ùƒ Ø³Ø¬Ù„ ØµÙˆØªÙƒ\", None\n",
        "        \n",
        "        user_text, response, audio_response = voice_chat(pipe, tokenizer, audio_file)\n",
        "        \n",
        "        return f\"ğŸ¤ Ø³Ø¤Ø§Ù„Ùƒ: {user_text}\\n\\nğŸ¤– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {response}\", audio_response\n",
        "    \n",
        "    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Gradio Ù…Ø­Ø³Ù†Ø©\n",
        "    with gr.Blocks(\n",
        "        title=\"Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ - ÙˆØ§Ø¬Ù‡Ø© Ù…Ø­Ø³Ù†Ø©\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            max-width: 1200px !important;\n",
        "            margin: auto !important;\n",
        "        }\n",
        "        .main-header {\n",
        "            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            padding: 2rem;\n",
        "            border-radius: 10px;\n",
        "            text-align: center;\n",
        "            margin-bottom: 2rem;\n",
        "        }\n",
        "        .chat-message {\n",
        "            padding: 1rem;\n",
        "            border-radius: 15px;\n",
        "            margin: 1rem 0;\n",
        "            max-width: 80%;\n",
        "        }\n",
        "        .user-message {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            margin-left: auto;\n",
        "        }\n",
        "        .bot-message {\n",
        "            background: white;\n",
        "            color: #333;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            margin-right: auto;\n",
        "        }\n",
        "        \"\"\"\n",
        "    ) as interface:\n",
        "        \n",
        "        # Header Ù…Ø­Ø³Ù†\n",
        "        gr.Markdown(\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1>ğŸ“ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ</h1>\n",
        "            <p>ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ø³ØªÙˆØ±Ø¯Ø© Ù…Ù† Flowise - ØªÙØ§Ø¹Ù„ Ø°ÙƒÙŠ Ù…Ø¹ Ø§Ù„Ø·Ù„Ø§Ø¨</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        \n",
        "        # Tabs Ù…Ø­Ø³Ù†Ø©\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ©\"):\n",
        "                gr.Markdown(\"### ğŸ’¬ ØªÙØ§Ø¹Ù„ Ù†ØµÙŠ Ø°ÙƒÙŠ\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=3):\n",
        "                        text_input = gr.Textbox(\n",
        "                            label=\"Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§\",\n",
        "                            placeholder=\"Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ\",\n",
        "                            lines=3\n",
        "                        )\n",
        "                        text_btn = gr.Button(\"ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„\", variant=\"primary\", size=\"lg\")\n",
        "                    \n",
        "                    with gr.Column(scale=2):\n",
        "                        text_output = gr.Textbox(\n",
        "                            label=\"ğŸ¤– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\",\n",
        "                            lines=10,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                \n",
        "                text_btn.click(\n",
        "                    process_text_input,\n",
        "                    inputs=text_input,\n",
        "                    outputs=text_output\n",
        "                )\n",
        "            \n",
        "            with gr.Tab(\"ğŸ¤ Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ©\"):\n",
        "                gr.Markdown(\"### ğŸ¤ ØªÙØ§Ø¹Ù„ ØµÙˆØªÙŠ Ù…ØªÙ‚Ø¯Ù…\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=2):\n",
        "                        audio_input = gr.Audio(\n",
        "                            label=\"Ø³Ø¬Ù„ ØµÙˆØªÙƒ\",\n",
        "                            type=\"filepath\",\n",
        "                            format=\"mp3\"\n",
        "                        )\n",
        "                        voice_btn = gr.Button(\"ğŸ¤ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª\", variant=\"primary\", size=\"lg\")\n",
        "                    \n",
        "                    with gr.Column(scale=3):\n",
        "                        voice_output = gr.Textbox(\n",
        "                            label=\"Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©\",\n",
        "                            lines=8,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        audio_output = gr.Audio(\n",
        "                            label=\"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµÙˆØªÙŠØ©\",\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "                \n",
        "                voice_btn.click(\n",
        "                    process_voice_input,\n",
        "                    inputs=audio_input,\n",
        "                    outputs=[voice_output, audio_output]\n",
        "                )\n",
        "            \n",
        "            with gr.Tab(\"ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª\"):\n",
        "                gr.Markdown(\"### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        **ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**\n",
        "                        - Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø©\n",
        "                        - ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£ÙŠ Ù…ÙˆØ¶ÙˆØ¹ ØªØ¹Ù„ÙŠÙ…ÙŠ\n",
        "                        - Ø¬Ø±Ø¨ Ø£Ø³Ø§Ù„ÙŠØ¨ Ù…Ø®ØªÙ„ÙØ© ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„\n",
        "                        - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª\n",
        "                        \"\"\")\n",
        "                    \n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        **ğŸ¯ Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©:**\n",
        "                        - ØªØµÙ…ÙŠÙ… Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø³ØªÙˆØ±Ø¯ Ù…Ù† Flowise\n",
        "                        - Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ\n",
        "                        - Ø£Ø²Ø±Ø§Ø± Ø³Ø±ÙŠØ¹Ø© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©\n",
        "                        - ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨ØµÙŠØºØ© JSON\n",
        "                        \"\"\")\n",
        "        \n",
        "        # Footer\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **ğŸ“ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ** | ÙˆØ§Ø¬Ù‡Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø³ØªÙˆØ±Ø¯Ø© Ù…Ù† Flowise\n",
        "        \"\"\")\n",
        "    \n",
        "    return interface\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ¹Ø±ÙŠÙ ÙˆØ§Ø¬Ù‡Ø© Gradio!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
        "print(\"ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ…...\")\n",
        "print(\"â° Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ:\", datetime.now())\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
        "interface = create_education_interface()\n",
        "\n",
        "# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
        "interface.launch(\n",
        "    share=True,  # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø¹Ø§Ù…\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    show_error=True,\n",
        "    debug=True  # Ø¥Ø¶Ø§ÙØ© debug\n",
        ")\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "print(\"ğŸŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¹Ø¨Ø± Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶ Ø£Ø¹Ù„Ø§Ù‡\")\n",
        "print(\"ğŸ’¡ Ø¥Ø°Ø§ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø·ØŒ Ø´ØºÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
